[2025-10-22 10:13:37] Combined live log → onnx/out.txt
[2025-10-22 10:13:37] Skipping build (export=0) — inference only.
[2025-10-22 10:13:37] ========= INFERENCE STAGE =========
[2025-10-22 10:13:37] Inference vggt-8x3x518x518_bf16 — 100 iters on images (examples/room/images)
[10/22/2025-10:13:38] [TRT] [I] Loaded engine size: 2324 MiB
[10/22/2025-10:13:38] [TRT] [V] Deserialization required 165548 microseconds.
[INFO] Loaded engine: onnx_exports/vggt-8x3x518x518_bf16.engine
/home/ashim/Documents/projects/vggt/onnx/trt_inference.py:136: DeprecationWarning: Use Implicit batch dimensions support has been removed instead.
  if self.engine.has_implicit_batch_dimension:
[10/22/2025-10:13:38] [TRT] [W] hasImplicitBatchDimension is deprecated and always return false.
[10/22/2025-10:13:38] [TRT] [I] [MS] Running engine with multi stream info
[10/22/2025-10:13:38] [TRT] [I] [MS] Number of aux streams is 5
[10/22/2025-10:13:38] [TRT] [I] [MS] Number of total worker streams is 6
[10/22/2025-10:13:38] [TRT] [I] [MS] The main stream provided by execute/enqueue calls is the first worker stream
[10/22/2025-10:13:38] [TRT] [V] Total per-runner device persistent memory is 224256
[10/22/2025-10:13:38] [TRT] [V] Total per-runner host persistent memory is 21840
[10/22/2025-10:13:38] [TRT] [V] Allocated device scratch memory of size 3914145792
[10/22/2025-10:13:38] [TRT] [V] - Runner scratch: 3914145792 bytes
[10/22/2025-10:13:38] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +3734, now: CPU 0, GPU 6043 (MiB)
[10/22/2025-10:13:38] [TRT] [V] CUDA lazy loading is enabled.
[INFO] TRT version: 10.11.0.33
[INFO] Execution mode: execute_async_v3
[INFO] Bindings:
  IN   0 images                           (8, 3, 518, 518) <class 'numpy.float32'> 25.76 MB
  OUT  1 cat_322                          (1, 8, 9) <class 'numpy.float32'> 0.00 MB
  OUT  2 view_411                         (1, 8, 518, 518, 1) <class 'numpy.float32'> 8.59 MB
  OUT  3 view_412                         (1, 8, 518, 518) <class 'numpy.float32'> 8.59 MB
  OUT  4 view_451                         (1, 8, 518, 518, 3) <class 'numpy.float32'> 25.76 MB
  OUT  5 view_452                         (1, 8, 518, 518) <class 'numpy.float32'> 8.59 MB
  OUT  6 unsqueeze                        (1, 8, 3, 518, 518) <class 'numpy.float32'> 25.76 MB
[INFO] Loading 8 images from examples/room/images

[INFO] Output diagnostics (first run):
  out0: name=cat_322                          shape=(1, 8, 9) dtype=float32 min=-0.839844 max=1 mean=0.235215
  out1: name=view_411                         shape=(1, 8, 518, 518, 1) dtype=float32 min=0.351562 max=2.60938 mean=0.876934
  out2: name=view_412                         shape=(1, 8, 518, 518) dtype=float32 min=1 max=2.89062 mean=1.90933
  out3: name=view_451                         shape=(1, 8, 518, 518, 3) dtype=float32 min=-2.39062 max=1.73438 mean=0.256768
  out4: name=view_452                         shape=(1, 8, 518, 518) dtype=float32 min=1 max=2.42188 mean=1.08093
  out5: name=unsqueeze                        shape=(1, 8, 3, 518, 518) dtype=float32 min=0 max=1 mean=0.539548

========== Performance Stats ==========
          iterations: 100
       H2D mean (ms): 1.420
   Compute mean (ms): 227.907
       D2H mean (ms): 3.090
     Total mean (ms): 232.417
      Total std (ms): 0.830
      Total min (ms): 231.285
      Total max (ms): 239.097
         FPS (batch): 4.30

✗ Below real-time: 4.3 FPS (232.4ms > 33.3ms)
  Consider: --use-random to test pure model performance

Camera-level throughput: 34.4 camera-FPS (8 cameras × 4.3 batch-FPS)
[2025-10-22 10:14:07] Inference vggt-8x3x518x518_fp16 — 100 iters on images (examples/room/images)
[10/22/2025-10:14:08] [TRT] [I] Loaded engine size: 2313 MiB
[10/22/2025-10:14:08] [TRT] [V] Deserialization required 163096 microseconds.
[INFO] Loaded engine: onnx_exports/vggt-8x3x518x518_fp16.engine
/home/ashim/Documents/projects/vggt/onnx/trt_inference.py:136: DeprecationWarning: Use Implicit batch dimensions support has been removed instead.
  if self.engine.has_implicit_batch_dimension:
[10/22/2025-10:14:08] [TRT] [W] hasImplicitBatchDimension is deprecated and always return false.
[10/22/2025-10:14:08] [TRT] [I] [MS] Running engine with multi stream info
[10/22/2025-10:14:08] [TRT] [I] [MS] Number of aux streams is 5
[10/22/2025-10:14:08] [TRT] [I] [MS] Number of total worker streams is 6
[10/22/2025-10:14:08] [TRT] [I] [MS] The main stream provided by execute/enqueue calls is the first worker stream
[10/22/2025-10:14:08] [TRT] [V] Total per-runner device persistent memory is 224256
[10/22/2025-10:14:08] [TRT] [V] Total per-runner host persistent memory is 19040
[10/22/2025-10:14:08] [TRT] [V] Allocated device scratch memory of size 2986298880
[10/22/2025-10:14:08] [TRT] [V] - Runner scratch: 2986298880 bytes
[10/22/2025-10:14:08] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +2848, now: CPU 0, GPU 5128 (MiB)
[10/22/2025-10:14:08] [TRT] [V] CUDA lazy loading is enabled.
[INFO] TRT version: 10.11.0.33
[INFO] Execution mode: execute_async_v3
[INFO] Bindings:
  IN   0 images                           (8, 3, 518, 518) <class 'numpy.float32'> 25.76 MB
  OUT  1 cat_322                          (1, 8, 9) <class 'numpy.float32'> 0.00 MB
  OUT  2 view_411                         (1, 8, 518, 518, 1) <class 'numpy.float32'> 8.59 MB
  OUT  3 view_412                         (1, 8, 518, 518) <class 'numpy.float32'> 8.59 MB
  OUT  4 view_451                         (1, 8, 518, 518, 3) <class 'numpy.float32'> 25.76 MB
  OUT  5 view_452                         (1, 8, 518, 518) <class 'numpy.float32'> 8.59 MB
  OUT  6 unsqueeze                        (1, 8, 3, 518, 518) <class 'numpy.float32'> 25.76 MB
[INFO] Loading 8 images from examples/room/images

[INFO] Output diagnostics (first run):
  out0: name=cat_322                          shape=(1, 8, 9) dtype=float32 min=-0.834473 max=1.00098 mean=0.270259
  out1: name=view_411                         shape=(1, 8, 518, 518, 1) dtype=float32 min=0.355225 max=2.60352 mean=0.87525
  out2: name=view_412                         shape=(1, 8, 518, 518) dtype=float32 min=1 max=2.86133 mean=1.89359
  out3: name=view_451                         shape=(1, 8, 518, 518, 3) dtype=float32 min=-2.40039 max=1.72266 mean=0.255249
  out4: name=view_452                         shape=(1, 8, 518, 518) dtype=float32 min=1 max=2.32422 mean=1.07403
  out5: name=unsqueeze                        shape=(1, 8, 3, 518, 518) dtype=float32 min=0 max=1 mean=0.538725

========== Performance Stats ==========
          iterations: 100
       H2D mean (ms): 1.461
   Compute mean (ms): 166.355
       D2H mean (ms): 3.095
     Total mean (ms): 170.911
      Total std (ms): 0.583
      Total min (ms): 169.307
      Total max (ms): 172.495
         FPS (batch): 5.85

✗ Below real-time: 5.9 FPS (170.9ms > 33.3ms)
  Consider: --use-random to test pure model performance

Camera-level throughput: 46.8 camera-FPS (8 cameras × 5.9 batch-FPS)
[2025-10-22 10:14:29] Inference vggt-8x3x518x518_fp8 — 100 iters on images (examples/room/images)
[10/22/2025-10:14:30] [TRT] [I] Loaded engine size: 2335 MiB
[10/22/2025-10:14:30] [TRT] [V] Deserialization required 193606 microseconds.
[INFO] Loaded engine: onnx_exports/vggt-8x3x518x518_fp8.engine
/home/ashim/Documents/projects/vggt/onnx/trt_inference.py:136: DeprecationWarning: Use Implicit batch dimensions support has been removed instead.
  if self.engine.has_implicit_batch_dimension:
[10/22/2025-10:14:30] [TRT] [W] hasImplicitBatchDimension is deprecated and always return false.
[10/22/2025-10:14:30] [TRT] [I] [MS] Running engine with multi stream info
[10/22/2025-10:14:30] [TRT] [I] [MS] Number of aux streams is 2
[10/22/2025-10:14:30] [TRT] [I] [MS] Number of total worker streams is 3
[10/22/2025-10:14:30] [TRT] [I] [MS] The main stream provided by execute/enqueue calls is the first worker stream
[10/22/2025-10:14:30] [TRT] [V] Total per-runner device persistent memory is 224256
[10/22/2025-10:14:30] [TRT] [V] Total per-runner host persistent memory is 377968
[10/22/2025-10:14:30] [TRT] [V] Allocated device scratch memory of size 2816569344
[10/22/2025-10:14:30] [TRT] [V] - Runner scratch: 2816569344 bytes
[10/22/2025-10:14:31] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +2686, now: CPU 0, GPU 4988 (MiB)
[10/22/2025-10:14:31] [TRT] [V] CUDA lazy loading is enabled.
[INFO] TRT version: 10.11.0.33
[INFO] Execution mode: execute_async_v3
[INFO] Bindings:
  IN   0 images                           (8, 3, 518, 518) <class 'numpy.float32'> 25.76 MB
  OUT  1 cat_322                          (1, 8, 9) <class 'numpy.float32'> 0.00 MB
  OUT  2 view_411                         (1, 8, 518, 518, 1) <class 'numpy.float32'> 8.59 MB
  OUT  3 view_412                         (1, 8, 518, 518) <class 'numpy.float32'> 8.59 MB
  OUT  4 view_451                         (1, 8, 518, 518, 3) <class 'numpy.float32'> 25.76 MB
  OUT  5 view_452                         (1, 8, 518, 518) <class 'numpy.float32'> 8.59 MB
  OUT  6 unsqueeze                        (1, 8, 3, 518, 518) <class 'numpy.float32'> 25.76 MB
[INFO] Loading 8 images from examples/room/images

[INFO] Output diagnostics (first run):
  out0: name=cat_322                          shape=(1, 8, 9) dtype=float32 min=-0.833984 max=1.00098 mean=0.269113
  out1: name=view_411                         shape=(1, 8, 518, 518, 1) dtype=float32 min=0.355469 max=2.59961 mean=0.874661
  out2: name=view_412                         shape=(1, 8, 518, 518) dtype=float32 min=1 max=2.83008 mean=1.88941
  out3: name=view_451                         shape=(1, 8, 518, 518, 3) dtype=float32 min=-2.39258 max=1.72266 mean=0.255325
  out4: name=view_452                         shape=(1, 8, 518, 518) dtype=float32 min=1 max=2.31641 mean=1.07301
  out5: name=unsqueeze                        shape=(1, 8, 3, 518, 518) dtype=float32 min=0 max=1 mean=0.538727

========== Performance Stats ==========
          iterations: 100
       H2D mean (ms): 1.473
   Compute mean (ms): 168.387
       D2H mean (ms): 3.079
     Total mean (ms): 172.940
      Total std (ms): 0.680
      Total min (ms): 171.435
      Total max (ms): 174.674
         FPS (batch): 5.78

✗ Below real-time: 5.8 FPS (172.9ms > 33.3ms)
  Consider: --use-random to test pure model performance

Camera-level throughput: 46.3 camera-FPS (8 cameras × 5.8 batch-FPS)
[2025-10-22 10:14:52] All done.
=float32 min=-2.39258 max=1.72266 mean=0.255325
  out4: name=view_452                         shape=(1, 8, 518, 518) dtype=float32 min=1 max=2.31641 mean=1.07301
  out5: name=unsqueeze                        shape=(1, 8, 3, 518, 518) dtype=float32 min=0 max=1 mean=0.538727

========== Performance Stats ==========
          iterations: 100
       H2D mean (ms): 1.473
   Compute mean (ms): 168.387
       D2H mean (ms): 3.079
     Total mean (ms): 172.940
      Total std (ms): 0.680
      Total min (ms): 171.435
      Total max (ms): 174.674
         FPS (batch): 5.78

✗ Below real-time: 5.8 FPS (172.9ms > 33.3ms)
  Consider: --use-random to test pure model performance

Camera-level throughput: 46.3 camera-FPS (8 cameras × 5.8 batch-FPS)
[2025-10-22 10:14:52] All done.
